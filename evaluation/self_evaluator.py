# core/self_evaluator.py - ç­–ç•¥æ¨¡å¼è‡ªé€‚åº”è¯„ä¼°å™¨ï¼ˆå®ä¹ é¢è¯•ç‰ˆï¼‰
from dataclasses import dataclass
from typing import List, Dict, Any
from langchain_core.documents import Document
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
import re
import time

from tests.test_monitor import monitor_evaluation


@dataclass
class ReviewResult:
    """è¯„ä¼°ç»“æœ"""
    confidence: float
    retrieval_relevance: float
    answer_completeness: float
    hallucination_risk: float
    latency_ms: int
    needs_human_review: bool
    review_comment: str = ""


class SelfEvaluator:
    """Self-RAG è¯„ä¼°å™¨ - è‡ªåŠ¨é€‚é…å°æ¨¡å‹(è§„åˆ™)å’Œå¤§æ¨¡å‹(LLMéªŒè¯)"""

    def __init__(self, llm, config):
        self.llm = llm
        self.config = config

        # ä»ç­–ç•¥é…ç½®è·å–å‚æ•°ï¼ˆè‡ªåŠ¨é€‚é…å°/å¤§æ¨¡å‹ï¼‰
        self.use_llm_contradiction = getattr(config, 'use_llm_contradiction', False)
        self.extract_claims_max = getattr(config, 'extract_claims_max', 3)
        self.strict_mode = getattr(config, 'strict_mode', False)
        self.human_review_threshold = getattr(config, 'human_review_threshold', 0.4)

        # æ‰“å°å½“å‰ç­–ç•¥ï¼ˆä¸€ç›®äº†ç„¶ï¼‰
        model_type = "å¤§æ¨¡å‹(LLMçŸ›ç›¾æ£€æµ‹)" if self.use_llm_contradiction else "å°æ¨¡å‹(è§„åˆ™çŸ›ç›¾æ£€æµ‹)"
        print(f"ğŸ“Š è¯„ä¼°å™¨åˆå§‹åŒ–: {model_type}, ä¸¥æ ¼æ¨¡å¼={self.strict_mode}")

        # åˆå§‹åŒ–æç¤ºè¯
        self._init_prompts()

    def _init_prompts(self):
        """åˆå§‹åŒ–æç¤ºè¯ï¼ˆå°æ¨¡å‹æç®€ï¼Œå¤§æ¨¡å‹è¯¦ç»†ï¼‰"""
        if self.strict_mode:
            # å¤§æ¨¡å‹ï¼šè¯¦ç»†æç¤ºè¯
            self.confidence_prompt = PromptTemplate.from_template(
                """è¯„ä¼°å›ç­”è´¨é‡ï¼ˆ0-1åˆ†ï¼‰ï¼Œä¸¥æ ¼åŒºåˆ†äº‹å®ä¸æ¨æµ‹ï¼š

                0.9-1.0ï¼šå®Œå…¨åŸºäºèµ„æ–™ï¼Œæ— å¤–éƒ¨æ¨æµ‹
                0.7-0.8ï¼šåŸºäºèµ„æ–™ï¼Œå«å¿…è¦æœ¯è¯­è§£é‡Š
                0.5-0.6ï¼šéƒ¨åˆ†åŸºäºèµ„æ–™ï¼Œéƒ¨åˆ†åˆç†æ¨æ–­
                0.3-0.4ï¼šå¤§å¤šæ¨æµ‹ï¼Œä¸èµ„æ–™å…³è”å¼±
                0.0-0.2ï¼šä¸èµ„æ–™çŸ›ç›¾æˆ–æ— æ³•éªŒè¯

                åªè¿”å›0-1ä¹‹é—´çš„æ•°å­—ï¼Œå°æ•°ç‚¹å1ä½ã€‚

                èµ„æ–™ï¼š{context}
                é—®é¢˜ï¼š{query}
                å›ç­”ï¼š{answer}
                è¯„åˆ†ï¼š"""
            )
        else:
            # å°æ¨¡å‹ï¼šæç®€æç¤ºè¯ï¼ˆé˜²è¶…æ—¶ï¼‰
            self.confidence_prompt = PromptTemplate.from_template(
                "è¯„ä¼°è´¨é‡(0-1)ï¼Œåªè¿”å›æ•°å­—ã€‚èµ„æ–™ï¼š{context} é—®é¢˜ï¼š{query} å›ç­”ï¼š{answer} åˆ†æ•°ï¼š"
            )

        self.confidence_chain = self.confidence_prompt | self.llm | StrOutputParser()

    @monitor_evaluation
    def evaluate(self, query: str, answer: str, documents: List[Document], latency_ms: int) -> ReviewResult:
        """
        ä¸»è¯„ä¼°å…¥å£ - å†…éƒ¨å®¹é”™ï¼Œå¯¹å¤–å§‹ç»ˆè¿”å›åˆæ³•ç»“æœ
        è‡ªåŠ¨é€‚é…ï¼šå°æ¨¡å‹å¿«é€Ÿè¯„ä¼°ï¼Œå¤§æ¨¡å‹ç²¾å‡†è¯„ä¼°
        """

        def safe_eval(func, default, *args, **kwargs):
            """å®‰å…¨æ‰§è¡Œè¯„ä¼°å‡½æ•°ï¼Œå¼‚å¸¸æ—¶è¿”å›é»˜è®¤å€¼"""
            try:
                return func(*args, **kwargs)
            except Exception as e:
                print(f"âš ï¸ è¯„ä¼°å­é¡¹å¤±è´¥({func.__name__}): {e}")
                return default

        start_time = time.time()

        # å¹¶è¡Œè®¡ç®—å„ç»´åº¦ï¼ˆå¸¦å®¹é”™ï¼‰
        confidence = safe_eval(self._evaluate_confidence, 0.6, answer)
        retrieval_relevance = safe_eval(self._evaluate_retrieval_relevance, 0.5, query, documents)
        answer_completeness = safe_eval(self._evaluate_completeness, 0.6, query, answer)
        hallucination_risk = safe_eval(self._evaluate_hallucination_risk, 0.5, answer, documents)

        eval_latency = int((time.time() - start_time) * 1000)

        # ç»„åˆç­–ç•¥è§¦å‘å®¡æ ¸ï¼ˆé¿å…å•ä¸€æŒ‡æ ‡è¯¯æ€ï¼‰
        needs_review = False
        if getattr(self.config, 'human_review_enabled', False):
            # ç­–ç•¥ï¼šä½ç½®ä¿¡åº¦ + é«˜å¹»è§‰ åŒæ—¶æ»¡è¶³ï¼Œæˆ–æ£€ç´¢å®Œå…¨å¤±è´¥
            if (confidence < self.human_review_threshold and hallucination_risk > 0.6):
                needs_review = True
            elif retrieval_relevance < 0.2:
                needs_review = True

        return ReviewResult(
            confidence=confidence,
            retrieval_relevance=retrieval_relevance,
            answer_completeness=answer_completeness,
            hallucination_risk=hallucination_risk,
            latency_ms=latency_ms + eval_latency,
            needs_human_review=needs_review,
            review_comment="è¯„ä¼°å®Œæˆ"
        )

    def _evaluate_confidence(self, answer: str) -> float:
        """ç½®ä¿¡åº¦è¯„ä¼° - è§£ææ•°å­—å¹¶å½’ä¸€åŒ–"""
        result = self.confidence_chain.invoke({
            "answer": answer[:500],
            "context": "",
            "query": ""
        }).strip()

        # æå–æ•°å­—ï¼ˆé€‚é…å„ç§æ ¼å¼ï¼‰
        m = re.search(r"(0?\.\d+|1\.0|1)", result)
        if m:
            score = float(m.group(1))
            # æ™ºèƒ½å½’ä¸€åŒ–ï¼šå¦‚æœæ˜¯8-10åˆ†åˆ¶ï¼Œè½¬ä¸º0-1
            if score > 1.0 and score <= 10:
                score = score / 10
            return min(max(score, 0.0), 1.0)
        return 0.6

    def _evaluate_retrieval_relevance(self, query: str, documents: List[Document]) -> float:
        """æ£€ç´¢ç›¸å…³æ€§ - åŸºäºæ–‡æ¡£åˆ†æ•°"""
        if not documents:
            return 0.0

        doc_scores = []
        for doc in documents[:3]:
            score = (doc.metadata.get("rerank_score") or
                     doc.metadata.get("hybrid_score") or
                     doc.metadata.get("vector_score") or
                     doc.metadata.get("bm25_score") or
                     doc.metadata.get("score", 0.0))

            if score is not None:
                doc_scores.append(float(score))

        # æ²¡æœ‰åˆ†æ•°ä½†æœ‰æ–‡æ¡£ï¼Œç»™ä¸­ç­‰åˆ†ï¼ˆå°æ¨¡å‹å®½å®¹ç­–ç•¥ï¼‰
        if not doc_scores and documents:
            return 0.6 if not self.strict_mode else 0.4

        return max(doc_scores) if doc_scores else 0.0

    def _evaluate_completeness(self, query: str, answer: str) -> float:
        """å›ç­”å®Œæ•´æ€§ - å°æ¨¡å‹ç”¨å¯å‘å¼ï¼Œå¤§æ¨¡å‹ç”¨LLMåˆ¤æ–­"""

        # å°æ¨¡å‹ç­–ç•¥ï¼šç®€å•å¯å‘å¼ï¼ˆä¸è°ƒç”¨LLMï¼Œçœèµ„æºï¼‰
        if not self.strict_mode:
            length = len(answer)
            if 50 <= length <= 200:
                return 0.8
            elif length > 20:
                return 0.6
            else:
                return 0.3

        # å¤§æ¨¡å‹ç­–ç•¥ï¼šLLMåˆ¤æ–­ï¼ˆç²¾å‡†ä½†è€—èµ„æºï¼‰
        prompt = f"""é—®é¢˜ï¼š{query}
        å›ç­”ï¼š{answer[:300]}

        è¯„ä¼°å›ç­”å®Œæ•´æ€§ï¼ˆ0-1ï¼‰ï¼š
        - 1.0ï¼šå…¨é¢è¦†ç›–æ‰€æœ‰è¦ç‚¹
        - 0.6-0.9ï¼šå›ç­”äº†ä¸»è¦éƒ¨åˆ†  
        - <0.6ï¼šé—æ¼å…³é”®ä¿¡æ¯

        åªè¿”å›æ•°å­—ï¼š"""

        try:
            result = self.llm.invoke(prompt).strip()
            match = re.search(r'(\d+\.?\d*)', result)
            score = float(match.group(1)) if match else 0.6
            return min(max(score, 0.0), 1.0)
        except:
            return 0.6

    def _evaluate_hallucination_risk(self, answer: str, documents: List[Document]) -> float:
        """
        å¹»è§‰é£é™©è¯„ä¼° - ç­–ç•¥æ¨¡å¼æ ¸å¿ƒ
        å°æ¨¡å‹ï¼šè§„åˆ™æ£€æµ‹ï¼ˆå¿«é€Ÿï¼‰
        å¤§æ¨¡å‹ï¼šLLMéªŒè¯ï¼ˆç²¾å‡†ï¼‰
        """
        if not documents:
            return 1.0

        claims = self._extract_claims(answer)
        if not claims:
            return 0.0

        # æ£€æµ‹æœªæ”¯æ’‘çš„é™ˆè¿°
        unsupported = 0
        for claim in claims:
            # ç­–ç•¥é€‰æ‹©ï¼šå¤§æ¨¡å‹ç”¨LLMéªŒè¯ï¼Œå°æ¨¡å‹ç”¨è§„åˆ™
            is_supported = self._is_supported_by_docs(claim, documents)

            if not is_supported:
                # å°æ¨¡å‹å®½å®¹ï¼šçŸ­å¥(<15å­—)ä¸è§†ä¸ºå¹»è§‰ï¼ˆå¯èƒ½æ˜¯å¸¸è¯†ï¼‰
                if not self.strict_mode and len(claim) < 15:
                    continue
                unsupported += 1

        if not claims:
            return 0.0

        # è®¡ç®—é£é™©æ¯”ä¾‹ï¼ˆå°æ¨¡å‹å°é¡¶0.8é¿å…è¿‡åº¦æƒ©ç½šï¼‰
        risk_ratio = unsupported / len(claims)
        max_risk = 0.8 if not self.strict_mode else 1.0

        return min(risk_ratio * 1.2, max_risk)

    def _extract_claims(self, answer: str) -> List[str]:
        """
        æå–äº‹å®é™ˆè¿° - ç­–ç•¥åŒ–
        å°æ¨¡å‹ï¼šç®€å•åˆ†å‰²ï¼ˆå¿«é€Ÿï¼Œä¸è€—tokenï¼‰
        å¤§æ¨¡å‹ï¼šLLMæå–ï¼ˆç²¾å‡†ï¼‰
        """
        if len(answer) < 20:
            return []

        max_claims = self.extract_claims_max

        # å°æ¨¡å‹ç­–ç•¥ï¼šç®€å•æŒ‰å¥å·åˆ†å‰²ï¼ˆä¸è°ƒç”¨LLMï¼‰
        if not self.strict_mode:
            import re
            # ä¿æŠ¤å°æ•°ç‚¹
            text = re.sub(r'(\d)\.(\d)', r'\1[DOT]\2', answer)
            sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]+', text)

            claims = []
            for s in sentences:
                s = s.strip().replace('[DOT]', '.')
                if len(s) > 5 and len(s) < 100:
                    claims.append(s)
            return claims[:max_claims]

        # å¤§æ¨¡å‹ç­–ç•¥ï¼šLLMæ™ºèƒ½æå–
        prompt = f"""ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–{max_claims}ä¸ªç‹¬ç«‹çš„äº‹å®é™ˆè¿°ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰ï¼š
        è¦æ±‚ï¼šæ˜ç¡®çš„ã€å¯éªŒè¯çš„çŸ­å¥ï¼Œä¸è¦æ€»ç»“æ€§è¯­å¥

        æ–‡æœ¬ï¼š{answer[:400]}

        äº‹å®é™ˆè¿°ï¼š"""

        try:
            result = self.llm.invoke(prompt).strip()
            claims = [
                line.strip() for line in result.split("\n")
                if line.strip() and len(line) > 5 and not line.startswith("â€¢")
            ]
            return claims[:max_claims]
        except Exception as e:
            print(f"âš ï¸ LLMæå–claimså¤±è´¥: {e}ï¼Œé€€å›åˆ°è§„åˆ™æå–")
            # å¤±è´¥æ—¶é€€å›åˆ°ç®€å•åˆ†å‰²
            return [s.strip() for s in answer.split("ã€‚") if len(s.strip()) > 10][:max_claims]

    def _is_supported_by_docs(self, claim: str, documents: List[Document]) -> bool:
        """
        æ£€æŸ¥é™ˆè¿°æ˜¯å¦æœ‰æ–‡æ¡£æ”¯æ’‘ - ç­–ç•¥æ¨¡å¼ç»Ÿä¸€å…¥å£
        æ ¹æ®é…ç½®è‡ªåŠ¨é€‰æ‹©è§„åˆ™æˆ–LLMéªŒè¯
        """
        if not claim or not documents:
            return False

        # ç­–ç•¥åˆ†æ”¯ï¼šå¤§æ¨¡å‹ç”¨LLMéªŒè¯ï¼Œå°æ¨¡å‹ç”¨è§„åˆ™
        if self.use_llm_contradiction:
            # å¤§æ¨¡å‹ï¼šç²¾å‡†LLMéªŒè¯
            return self._llm_contradiction_check(claim, documents)
        else:
            # å°æ¨¡å‹ï¼šè½»é‡çº§è§„åˆ™éªŒè¯
            return self._rule_contradiction_check(claim, documents)

    def _rule_contradiction_check(self, claim: str, documents: List[Document]) -> bool:
        """è½»é‡çº§è§„åˆ™æ£€æµ‹ï¼ˆå°æ¨¡å‹ç”¨ï¼‰- åŸºäºå…³é”®è¯åŒ¹é…"""
        claim_lower = claim.lower()

        # 1. ç®€å•å­ä¸²åŒ¹é…ï¼ˆå¿«é€Ÿï¼‰
        for doc in documents:
            if claim_lower in doc.page_content.lower():
                return True

        # 2. å…³é”®è¯åŒ¹é…ï¼ˆ60%ä»¥ä¸Šå…³é”®è¯å‡ºç°å³è®¤ä¸ºæ”¯æŒï¼‰
        claim_words = set(claim_lower.split())
        if len(claim_words) < 3:
            return False  # å¤ªçŸ­æ— æ³•åˆ¤æ–­

        for doc in documents:
            doc_text = doc.page_content.lower()
            doc_words = set(doc_text.split())
            overlap = len(claim_words & doc_words) / len(claim_words)
            if overlap > 0.6:
                return True

        return False

    def _llm_contradiction_check(self, claim: str, documents: List[Document]) -> bool:
        """
        LLM-basedçŸ›ç›¾æ£€æµ‹ï¼ˆå¤§æ¨¡å‹ç”¨ï¼‰- ç²¾å‡†ä½†è€—æ—¶
        é€‚ç”¨äº deepseek-33b/qwen-14b ç­‰å¤§æ¨¡å‹
        """
        # å–æœ€ç›¸å…³çš„1-2ç¯‡æ–‡æ¡£ï¼ˆèŠ‚çœtokenï¼‰
        sorted_docs = sorted(
            documents,
            key=lambda d: d.metadata.get("rerank_score", 0) or d.metadata.get("vector_score", 0),
            reverse=True
        )[:2]

        # æˆªæ–­æ–‡æ¡£å†…å®¹ï¼ˆé˜²æ­¢è¶…å‡ºä¸Šä¸‹æ–‡ï¼‰
        context_parts = []
        for i, doc in enumerate(sorted_docs, 1):
            content = doc.page_content[:300].replace("\n", " ")
            context_parts.append(f"[æ–‡æ¡£{i}] {content}...")

        context = "\n".join(context_parts)

        # æ˜ç¡®çš„ä¸‰åˆ†ç±»åˆ¤æ–­prompt
        prompt = f"""ä½œä¸ºäº‹å®æ ¸æŸ¥ä¸“å®¶ï¼Œåˆ¤æ–­ä»¥ä¸‹é™ˆè¿°æ˜¯å¦ä¸æä¾›çš„æ–‡æ¡£å†…å®¹çŸ›ç›¾ã€‚

ã€æ–‡æ¡£å†…å®¹ã€‘
{context}

ã€å¾…æ ¸æŸ¥é™ˆè¿°ã€‘
"{claim}"

ã€ä»»åŠ¡å®šä¹‰ã€‘
- "çŸ›ç›¾"ï¼šæ–‡æ¡£æ˜ç¡®è¯´äº†ä¸é™ˆè¿°ç›¸åçš„å†…å®¹ï¼ˆå¦‚æ–‡æ¡£è¯´"æ”¯æŒA"ï¼Œé™ˆè¿°è¯´"ä¸æ”¯æŒA"ï¼‰
- "ä¸çŸ›ç›¾"ï¼šæ–‡æ¡£æ”¯æŒè¯¥é™ˆè¿°ï¼Œæˆ–æ–‡æ¡£æœªæåŠè¯¥é™ˆè¿°ï¼ˆæ— æ³•éªŒè¯ä¸ç®—çŸ›ç›¾ï¼‰
- æ³¨æ„ï¼šæ–‡æ¡£æœªæåŠçš„å†…å®¹ä¸è¦åˆ¤ä¸ºçŸ›ç›¾ï¼Œåº”åˆ¤ä¸º"ä¸çŸ›ç›¾"

ã€è¾“å‡ºè¦æ±‚ã€‘
åªå›å¤ä»¥ä¸‹ä¸¤ä¸ªè¯ä¹‹ä¸€ï¼Œä¸è¦è§£é‡Šï¼š
çŸ›ç›¾ / ä¸çŸ›ç›¾

åˆ¤æ–­ç»“æœï¼š"""

        try:
            # è°ƒç”¨å¤§æ¨¡å‹åˆ¤æ–­
            result = self.llm.invoke(prompt).strip().lower()

            # è§£æç»“æœï¼ˆåŒ…å«"çŸ›ç›¾"ä¸”ä¸å«"ä¸çŸ›ç›¾"ï¼‰
            is_contradictory = ("çŸ›ç›¾" in result or "contradict" in result) and "ä¸çŸ›ç›¾" not in result

            if is_contradictory:
                print(f"  âš ï¸ LLMæ£€æµ‹åˆ°çŸ›ç›¾: '{claim[:30]}...'")

            # å¦‚æœçŸ›ç›¾ï¼Œè¿”å›Falseï¼ˆè¡¨ç¤º"ä¸æ”¯æŒ"ï¼‰
            # å¦‚æœä¸çŸ›ç›¾ï¼Œè¿”å›Trueï¼ˆè¡¨ç¤º"æ”¯æŒ"æˆ–"æ— æ³•éªŒè¯ä½†ä¸çŸ›ç›¾"ï¼‰
            return not is_contradictory

        except Exception as e:
            print(f"âš ï¸ LLMçŸ›ç›¾æ£€æµ‹å¤±è´¥: {e}ï¼Œé€€å›åˆ°è§„åˆ™æ£€æµ‹")
            # å¤±è´¥æ—¶é€€å›åˆ°è§„åˆ™æ£€æµ‹ï¼Œä¿è¯ä¸é˜»æ–­æµç¨‹
            return self._rule_contradiction_check(claim, documents)