# core/rag_chain.py
import asyncio
import time
import uuid
from typing import List, Dict, Any, Optional, Literal, Union
from pathlib import Path

from langchain_core.documents import Document
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.store.memory import InMemoryStore

# ========== å…³é”®å¯¼å…¥ï¼šinterrupt å’Œ Command ==========
from langgraph.types import Command, interrupt

from core.state import RAGState
from core.document_processor import DocumentProcessor
from core.retriever import Retriever
from core.generator import Generator
from evaluation.self_evaluator import SelfEvaluator
from config.setting import RAGConfig


class SelfRAGChain:
    """Self-RAG ä¸»é“¾ï¼šæ¨¡å—åŒ– + LangGraph + å¤šæ¨¡æ€å°±ç»ª + äººæœºåä½œï¼ˆé¢è¯•çº§å®ç°ï¼‰"""

    def __init__(self, config: RAGConfig):
        self.config = config
        self.review_tasks: Dict[str, Dict[str, Any]] = {}
        self.review_enabled = getattr(config, "human_review_enabled", False)

        # åˆå§‹åŒ–ç»„ä»¶
        self.processor = DocumentProcessor(config)
        self.generator = Generator(
            ollama_base_url=config.ollama_base_url,
            llm_model=config.llm_model,
            temperature=config.temperature
        )
        self.evaluator = SelfEvaluator(self.generator.llm, config)

        self.retriever = None  # åˆå§‹ä¸ºNoneï¼Œå°†åœ¨aindex_documentsä¸­è®¾ç½®
        self.review_tasks: Dict[str, Dict[str, Any]] = {}
        self.review_enabled = getattr(config, "human_review_enabled", False)

        # LangGraph Memory
        self.memory_store = InMemoryStore()
        self.checkpointer = InMemorySaver()
        self.graph = None
        self.session_id = "default"

    def enable_memory(self, session_id: str = "default"):
        """å¯ç”¨LangGraph Memory"""
        self.session_id = session_id

        if self.processor.vector_manager:
            embeddings = self.processor.vector_manager.embeddings
            self.memory_store = InMemoryStore(
                index={"embed": embeddings, "dims": 1024}
            )

        self.checkpointer = InMemorySaver()
        print(f"âœ… LangGraph Memory å·²å¯ç”¨ | ä¼šè¯: {session_id}")

    async def aindex_documents(self, texts: List[str], files: Optional[List[Union[Path, str]]] = None,
                               metadatas: Optional[List[Dict]] = None):
        """ç´¢å¼•æ–‡æ¡£ï¼ˆæ”¯æŒOCRï¼‰- ç»ˆæä¿®å¤ç‰ˆ"""
        if self.graph is not None:
            print("âš ï¸  å›¾å·²å­˜åœ¨ï¼Œè·³è¿‡é‡æ–°ç¼–è¯‘")
            return

        try:
            # 1. å¤„ç†æ–‡æ¡£å’ŒOCR
            vector_store = await self.processor.process(texts, files, metadatas)

            # 2. è·å–æ‰€æœ‰æ–‡æ¡£ï¼ˆåŒ…å«OCRï¼‰
            documents = []
            if self.processor.vector_manager:
                documents = self.processor.vector_manager.get_all_documents()

            # 3. ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªæ–‡æ¡£
            if not documents:
                print("âš ï¸  æœªè·å–åˆ°ä»»ä½•æ–‡æ¡£ï¼Œä½¿ç”¨ç©ºåˆ—è¡¨åˆå§‹åŒ–")
                documents = []

            # 4. åˆå§‹åŒ–æ£€ç´¢å™¨
            self.retriever = Retriever(vector_store, documents, self.config)

            # 5. æ„å»ºå›¾ï¼ˆç¡®ä¿graphè¢«èµ‹å€¼ï¼‰
            self.graph = self._build_graph()
            print(f"âœ… StateGraph ç¼–è¯‘å®Œæˆ | æ–‡æ¡£æ•°ï¼š{len(documents)}")

        except Exception as e:
            print(f"âŒ aindex_documents å¤±è´¥: {e}")
            raise

    def _build_graph(self):
        """æ„å»º Self-RAG å·¥ä½œæµ"""
        graph = StateGraph(RAGState)

        # æ·»åŠ èŠ‚ç‚¹ï¼ˆä½¿ç”¨å®ä¾‹æ–¹æ³•ä½œä¸ºèŠ‚ç‚¹å‡½æ•°ï¼‰
        graph.add_node("process_query", self._process_query_node)
        graph.add_node("retrieve", self._retrieve_node)
        graph.add_node("generate", self._generate_node)
        graph.add_node("evaluate", self._evaluate_node)
        graph.add_node("human_review", self._human_review_node)
        graph.add_node("refine", self._refine_node)
        graph.add_node("finalize", self._finalize_node)

        # å®šä¹‰æµç¨‹
        graph.add_edge(START, "process_query")
        graph.add_edge("process_query", "retrieve")
        graph.add_edge("retrieve", "generate")
        graph.add_edge("generate", "evaluate")

        # æ¡ä»¶åˆ†æ”¯
        graph.add_conditional_edges("evaluate", self._should_continue, {
            "refine": "refine",
            "human_review": "human_review",
            "finalize": "finalize"
        })

        graph.add_conditional_edges("human_review", self._should_continue_after_review, {
            "refine": "refine",
            "finalize": "finalize"
        })

        graph.add_edge("refine", "retrieve")
        graph.add_edge("finalize", END)

        # ç¼–è¯‘å›¾
        self.graph = graph.compile(
            checkpointer=self.checkpointer,
            store=self.memory_store,
            interrupt_before=["human_review"] if self.review_enabled else None
        )
        return self.graph

    # ========== èŠ‚ç‚¹å‡½æ•°å®šä¹‰ ==========
    def _get_review_reason(self, review) -> str:
        """è·å–å®¡æ ¸è§¦å‘åŸå› """
        reasons = []
        if review.confidence < self.config.human_review_threshold:
            reasons.append(f"ç½®ä¿¡åº¦è¿‡ä½({review.confidence:.2f})")
        if review.hallucination_risk > 0.5:
            reasons.append(f"å¹»è§‰é£é™©é«˜({review.hallucination_risk:.2f})")
        if review.retrieval_relevance < 0.3:
            reasons.append(f"æ£€ç´¢ç›¸å…³æ€§ä½({review.retrieval_relevance:.2f})")

        return " | ".join(reasons) if reasons else "æœªçŸ¥åŸå› "

    def _process_query_node(self, state: RAGState) -> RAGState:
        """å¤„ç†æŸ¥è¯¢èŠ‚ç‚¹"""
        query = state["query"]

        # OCRæ–‡æœ¬åˆå¹¶
        if state.get("ocr_texts"):
            query += " " + " ".join(state["ocr_texts"])
            print(f"ğŸ“· OCRæ–‡æœ¬å·²å¹¶å…¥æŸ¥è¯¢ï¼š{query[:50]}...")

        # æ£€ç´¢å†å²ä¸Šä¸‹æ–‡
        if self.memory_store:
            history_items = self.memory_store.search(
                (self.session_id, "conversations"),
                query=query,
                limit=2
            )
            state["history_context"] = "\n".join([
                item.value["text"] for item in history_items
            ])

        # æŸ¥è¯¢æ”¹å†™
        if state.get("chat_history"):
            rewritten = self.generator.rewrite_query(query, state["chat_history"])
            print(f"ğŸ”„ æŸ¥è¯¢æ”¹å†™ï¼š{query} â†’ {rewritten}")
            state["query"] = rewritten

        return state

    def _retrieve_node(self, state: RAGState) -> RAGState:
        """æ£€ç´¢èŠ‚ç‚¹ - å¢åŠ ç›¸å…³æ€§è¿‡æ»¤"""
        query = state["query"]

        # æ‰§è¡Œæ£€ç´¢
        docs = asyncio.run(self.retriever.retrieve(query))

        # æ·»åŠ å†å²ä¸Šä¸‹æ–‡ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        if state.get("history_context"):
            docs.insert(0, Document(
                page_content=state["history_context"],
                metadata={"source": "conversation_history", "score": 1.0}  # å†å²ç»™æ»¡åˆ†
            ))

        # ========== æ–°å¢ï¼šç›¸å…³æ€§è¿‡æ»¤ ==========
        if not docs:
            # å®Œå…¨æ— æ£€ç´¢ç»“æœ
            state["documents"] = []
            state["context"] = "ï¼ˆè­¦å‘Šï¼šæœªæ£€ç´¢åˆ°ä»»ä½•ç›¸å…³èµ„æ–™ï¼‰"
            state["sources"] = []
            print("âš ï¸ æœªæ£€ç´¢åˆ°ä»»ä½•æ–‡æ¡£")
            return state

        # è®¡ç®—æœ€é«˜ç›¸å…³æ€§åˆ†æ•°
        max_relevance = 0.0
        for doc in docs:
            # ä»metadataæå–å„ç§å¯èƒ½çš„åˆ†æ•°
            score = (doc.metadata.get("rerank_score") or
                     doc.metadata.get("hybrid_score") or
                     doc.metadata.get("vector_score") or
                     doc.metadata.get("bm25_score", 0.0))
            if score and score > max_relevance:
                max_relevance = float(score)

        # ç›¸å…³æ€§è¿‡ä½è¿‡æ»¤ï¼ˆé˜ˆå€¼0.3ï¼Œå¯é…ç½®ï¼‰
        relevance_threshold = getattr(self.config, 'retrieval_relevance_threshold', 0.2)

        if max_relevance < relevance_threshold:
            # ä½ç›¸å…³æ€§ï¼šæ¸…ç©ºä¸Šä¸‹æ–‡ï¼Œå¼ºåˆ¶æ¨¡å‹æ‹’ç­”
            state["documents"] = []  # æ¸…ç©ºæ–‡æ¡£åˆ—è¡¨
            state["context"] = f"ï¼ˆè­¦å‘Šï¼šæ£€ç´¢åˆ°çš„èµ„æ–™ä¸é—®é¢˜ç›¸å…³æ€§è¿‡ä½ï¼ˆ{max_relevance:.2f}ï¼‰ï¼ŒçŸ¥è¯†åº“ä¸­å¯èƒ½æ— ç›¸å…³èµ„æ–™ï¼‰"
            state["sources"] = []
            print(f"âš ï¸ æ£€ç´¢ç›¸å…³æ€§è¿‡ä½ï¼ˆ{max_relevance:.2f}ï¼‰ï¼Œæ¸…ç©ºä¸Šä¸‹æ–‡")
        else:
            # æ­£å¸¸æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
            context_parts = []
            sources = []
            for i, doc in enumerate(docs):
                context_parts.append(f"[æ–‡æ¡£ {i + 1}] {doc.page_content}")
                sources.append({
                    "source": doc.metadata.get("source", "unknown"),
                    "content_preview": doc.page_content[:30] + "..."
                })

            state["documents"] = docs
            state["context"] = "\n\n".join(context_parts)
            state["sources"] = sources
            print(f"ğŸ“š æ£€ç´¢åˆ° {len(docs)} ä¸ªç›¸å…³æ–‡æ¡£ï¼Œæœ€é«˜ç›¸å…³æ€§: {max_relevance:.2f}")

        return state

    def _generate_node(self, state: RAGState) -> RAGState:
        """ç”ŸæˆèŠ‚ç‚¹"""
        answer = self.generator.generate(
            query=state["query"],
            context=state["context"],
            chat_history=state.get("chat_history", [])
        )

        state["answer"] = answer
        print(f"ğŸ’¬ ç”Ÿæˆç­”æ¡ˆå®Œæˆ")
        return state

    def _evaluate_node(self, state: RAGState) -> RAGState:
        """è¯„ä¼°èŠ‚ç‚¹ - é’¢é“å®¹é”™ç‰ˆ"""
        try:
            # æ£€æŸ¥ç­”æ¡ˆå­˜åœ¨æ€§
            if not state.get("answer"):
                print("âš ï¸ ç­”æ¡ˆä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤è¯„ä¼°")
                state["confidence"] = 0.0
                state["iteration"] = 0
                state["review_result"] = {}
                return state

            # æ£€æŸ¥ documents æ˜¯å¦å­˜åœ¨
            if not state.get("documents"):
                print("âš ï¸ æ–‡æ¡£åˆ—è¡¨ä¸ºç©º")
                state["documents"] = []

            # æ‰§è¡Œè¯„ä¼°ï¼ˆå¸¦ç‹¬ç«‹try-exceptï¼‰
            try:
                review = self.evaluator.evaluate(
                    state["query"],
                    state["answer"],
                    state.get("documents", []),
                    0
                )
                confidence = review.confidence
                hallucination = review.hallucination_risk
                relevance = review.retrieval_relevance
                needs_review = review.needs_human_review

                state["review_result"] = review.__dict__

            except Exception as eval_err:
                print(f"âš ï¸ è¯„ä¼°å™¨å¼‚å¸¸: {eval_err}")
                confidence = 0.6
                hallucination = 0.5
                relevance = 0.5
                needs_review = False
                state["review_result"] = {"error": str(eval_err)}

            # æ›´æ–°çŠ¶æ€
            state["confidence"] = confidence
            state["iteration"] = state.get("iteration", 0) + 1

            print(f"ğŸ“Š è¯„ä¼°å®Œæˆ: ç½®ä¿¡åº¦={confidence:.2f}, å¹»è§‰={hallucination:.2f}, è¿­ä»£={state['iteration']}")

            # äººå·¥å®¡æ ¸é€»è¾‘ï¼ˆä»…åœ¨éœ€è¦æ—¶ï¼‰
            if needs_review and self.review_enabled:
                task_id = f"review_{uuid.uuid4().hex[:8]}"
                state["review_task_id"] = task_id
                state["review_status"] = "pending"
                state["review_trigger_reason"] = f"ç½®ä¿¡åº¦ä½({confidence:.2f})æˆ–å¹»è§‰é«˜({hallucination:.2f})"

                self.review_tasks[task_id] = {
                    "task_id": task_id,
                    "query": state["query"],
                    "original_answer": state["answer"],
                    "confidence": confidence,
                    "hallucination_risk": hallucination,
                    "retrieval_relevance": relevance,
                    "documents": state.get("documents", []),
                    "status": "pending",
                    "created_at": time.time(),
                    "trigger_reason": state["review_trigger_reason"]
                }
                print(f"âš ï¸ è§¦å‘äººå·¥å®¡æ ¸: {task_id}")

        except Exception as e:
            print(f"âŒ _evaluate_node ä¸¥é‡é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()

            # ç»å¯¹ä¸èƒ½å´©ï¼Œç»™é»˜è®¤å€¼
            state["confidence"] = 0.5
            state["iteration"] = 1
            state["review_result"] = {"error": str(e)}

        return state

    def _human_review_node(self, state: RAGState) -> Command[Literal["refine", "finalize"]]:
        """äººå·¥å®¡æ ¸èŠ‚ç‚¹ï¼ˆä½¿ç”¨interruptï¼‰"""
        task_id = state["review_task_id"]

        # ========== æ ¸å¿ƒï¼šä½¿ç”¨interruptæš‚åœæ‰§è¡Œ ==========
        decision = interrupt({
            "task_id": task_id,
            "query": state["query"],
            "original_answer": state["answer"],
            "confidence": state["confidence"],
            "trigger_reason": state["review_trigger_reason"],
            "message": "ç­‰å¾…äººå·¥å®¡æ ¸..."
        })

        # æ¢å¤æ‰§è¡Œåçš„å¤„ç†
        if decision is None:
            return Command(goto="finalize", update={"review_status": "approved"})

        if decision["action"] == "approved":
            return Command(goto="finalize", update={"review_status": "approved"})
        elif decision["action"] == "rejected":
            return Command(goto="refine", update={
                "review_status": "rejected",
                "query": state["query"] + " ï¼ˆè¯·é‡æ–°ç”Ÿæˆæ›´å‡†ç¡®çš„ç­”æ¡ˆï¼‰"
            })
        elif decision["action"] == "modified":
            return Command(goto="finalize", update={
                "review_status": "modified",
                "human_modified_answer": decision["modified_answer"],
                "review_comment": decision.get("comment", ""),
                "reviewer": decision.get("reviewer", "anonymous")
            })

        return Command(goto="finalize", update={"review_status": "approved"})

    def _refine_node(self, state: RAGState) -> RAGState:
        """ä¼˜åŒ–èŠ‚ç‚¹"""
        current_query = state["query"]
        if "ï¼ˆè¯·æä¾›æ›´è¯¦ç»†çš„å›ç­”ï¼‰" not in current_query:
            state["query"] = current_query + " ï¼ˆè¯·æä¾›æ›´è¯¦ç»†çš„å›ç­”ï¼‰"
        return state

    def _finalize_node(self, state: RAGState) -> RAGState:
        """ç»“æŸèŠ‚ç‚¹ï¼šä¿å­˜è®°å¿†"""
        # ä¿å­˜é«˜è´¨é‡å¯¹è¯åˆ°é•¿æœŸè®°å¿†
        if self.memory_store and state["confidence"] > 0.5:
            self.memory_store.put(
                (self.session_id, "conversations"),
                f"turn_{int(time.time())}",
                {"text": f"Q: {state['query']}\nA: {state['answer'][:200]}"}
            )

        # æ›´æ–°å®¡æ ¸ä»»åŠ¡çŠ¶æ€
        if state.get("review_task_id"):
            task_id = state["review_task_id"]
            if task_id in self.review_tasks:
                self.review_tasks[task_id]["status"] = state.get("review_status", "completed")
                self.review_tasks[task_id]["final_answer"] = state["answer"]
                self.review_tasks[task_id]["reviewed_at"] = time.time()
                self.review_tasks[task_id]["reviewer"] = state.get("reviewer")
                self.review_tasks[task_id]["review_comment"] = state.get("review_comment")

        return state

    # ========== æ¡ä»¶è·¯ç”±å‡½æ•° ==========

    def _should_continue(self, state: RAGState) -> Literal["refine", "human_review", "finalize"]:
        """è¯„ä¼°åçš„è·¯ç”±å†³ç­– - ä¼˜åŒ–å®¡æ ¸è§¦å‘"""
        iteration = state.get("iteration", 0)
        confidence = state.get("confidence", 0.0)
        relevance = state.get("review_result", {}).get("retrieval_relevance", 0.0)

        # å¦‚æœå·²ç»è§¦å‘å®¡æ ¸
        if state.get("review_task_id"):
            return "human_review"

        # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
        if iteration >= self.config.max_iterations:
            return "finalize"

        # ç½®ä¿¡åº¦è¶³å¤Ÿé«˜ä¸”ç›¸å…³æ€§ä¸ä½ï¼Œç›´æ¥ç»“æŸ
        if (confidence >= self.config.confidence_threshold and
                relevance >= self.config.retrieval_relevance_threshold):
            return "finalize"

        # å¦‚æœç›¸å…³æ€§æä½ï¼Œå³ä½¿ç½®ä¿¡åº¦é«˜ä¹Ÿå®¡æ ¸
        if relevance < self.config.retrieval_relevance_threshold:
            return "human_review"

        # å¦åˆ™ç»§ç»­ä¼˜åŒ–
        return "refine"

    def _should_continue_after_review(self, state: RAGState) -> Literal["refine", "finalize"]:
        """å®¡æ ¸åçš„è·¯ç”±å†³ç­–"""
        if state.get("human_modified_answer"):
            state["answer"] = state["human_modified_answer"]
            state["confidence"] = min(1.0, state.get("confidence", 0.0) + 0.2)
            return "finalize"

        if state.get("review_status") == "rejected":
            return "refine"

        return "finalize"

    # ========== å¤–éƒ¨ API æ¥å£ ==========

    def get_pending_reviews(self) -> List[Dict[str, Any]]:
        """è·å–å¾…å®¡æ ¸ä»»åŠ¡åˆ—è¡¨"""
        return [
            {
                "task_id": task["task_id"],
                "query": task["query"][:200] + "...",
                "confidence": task["confidence"],
                "hallucination_risk": task["hallucination_risk"],
                "retrieval_relevance": task["retrieval_relevance"],
                "trigger_reason": task["trigger_reason"],
                "created_at": task["created_at"]
            }
            for task in self.review_tasks.values()
            if task["status"] == "pending"
        ]

    def get_review_detail(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å®¡æ ¸ä»»åŠ¡è¯¦æƒ…"""
        task = self.review_tasks.get(task_id)
        if not task:
            return None

        return {
            "task_id": task["task_id"],
            "status": task["status"],
            "query": task["query"],
            "original_answer": task["original_answer"],
            "documents": [
                {
                    "source": doc.metadata.get("source", "unknown"),
                    "content": doc.page_content[:300] + "..."
                }
                for doc in task["documents"]
            ],
            "metrics": {
                "confidence": task["confidence"],
                "hallucination_risk": task["hallucination_risk"],
                "retrieval_relevance": task["retrieval_relevance"]
            },
            "trigger_reason": task["trigger_reason"],
            "created_at": task["created_at"]
        }

    def submit_review(self, task_id: str, action: str,
                      modified_answer: Optional[str] = None,
                      comment: Optional[str] = None,
                      reviewer: Optional[str] = None) -> bool:
        """æäº¤å®¡æ ¸ç»“æœï¼ˆä¸interrupté…åˆï¼‰"""
        if task_id not in self.review_tasks:
            print(f"âŒ å®¡æ ¸ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
            return False

        if self.review_tasks[task_id]["status"] != "pending":
            print(f"âŒ å®¡æ ¸ä»»åŠ¡çŠ¶æ€ä¸æ˜¯pending: {task_id}")
            return False

        # å‡†å¤‡å®¡æ ¸å†³ç­–
        decision = {
            "action": action,
            "reviewer": reviewer or "anonymous",
            "comment": comment or ""
        }

        if action == "modified":
            if not modified_answer:
                print(f"âŒ ä¿®æ”¹ç­”æ¡ˆä¸èƒ½ä¸ºç©º: {task_id}")
                return False
            decision["modified_answer"] = modified_answer

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        self.review_tasks[task_id].update({
            "status": action,
            "reviewer": decision["reviewer"],
            "review_comment": decision["comment"],
            "reviewed_at": time.time()
        })

        # ========== æ¢å¤å›¾æ‰§è¡Œ ==========
        try:
            config = {"configurable": {"thread_id": self.session_id}}

            # æ›´æ–°çŠ¶æ€å¹¶æ¢å¤æ‰§è¡Œ
            self.graph.update_state(
                config,
                decision,  # è¿™ä¼šä½œä¸ºinterruptçš„è¿”å›å€¼
                as_node="human_review"
            )

            # å¼‚æ­¥æ¢å¤
            asyncio.create_task(self._resume_execution(task_id))

            print(f"âœ… å®¡æ ¸æäº¤æˆåŠŸ: {task_id}")
            return True
        except Exception as e:
            print(f"âŒ æ¢å¤æ‰§è¡Œå¤±è´¥: {e}")
            return False

    async def _resume_execution(self, task_id: str):
        """å¼‚æ­¥æ¢å¤å›¾æ‰§è¡Œ"""
        try:
            config = {"configurable": {"thread_id": self.session_id}}
            async for chunk in self.graph.astream(None, config, stream_mode="updates"):
                if "__interrupt__" in chunk:
                    break
        except Exception as e:
            print(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {task_id} - {e}")

    async def query(self, question: str, chat_history: List[Dict[str, str]] = None,
                    files: Optional[List[Union[Path, str]]] = None) -> Dict[str, Any]:
        """æ‰§è¡ŒæŸ¥è¯¢ï¼ˆä¸»å…¥å£ï¼‰- OCRæ–‡ä»¶å·²åœ¨ç´¢å¼•æ—¶å¤„ç†"""
        if not self.graph:
            raise ValueError("è¯·å…ˆè°ƒç”¨ aindex_documents()")

        # æ³¨æ„ï¼šfileså‚æ•°ç°åœ¨ç”¨äºç´¢å¼•OCRæ–‡æ¡£ï¼Œè€ŒéæŸ¥è¯¢æ—¶å¤„ç†
        # å¦‚æœéœ€è¦æŸ¥è¯¢æ—¶ä¸´æ—¶ç´¢å¼•OCRæ–‡ä»¶ï¼Œè°ƒç”¨å‰éœ€å…ˆæ‰§è¡Œ aindex_documents
        if files:
            await self.aindex_documents([], files, [])

        initial_state = RAGState(
            query=question,
            chat_history=chat_history or [],
            documents=[],
            context="",
            answer="",
            sources=[],
            confidence=0.0,
            iteration=0,
            history_context="",
            review_result=None,
            ocr_texts=None,
            images=None,
            review_task_id=None,
            review_status=None,
            human_modified_answer=None,
            review_comment=None,
            reviewer=None,
            review_trigger_reason=None
        )

        result = await self.graph.ainvoke(
            initial_state,
            {"configurable": {"thread_id": self.session_id}}
        )

        return {
            "answer": result["answer"],
            "confidence": result["confidence"],
            "iteration": result["iteration"],
            "sources": result["sources"],
            "review_task_id": result.get("review_task_id"),
            "review_status": result.get("review_status"),
            "review_trigger_reason": result.get("review_trigger_reason")
        }