# core/agent_tools.py
from typing import Annotated, List, Optional
from pathlib import Path
from langchain_core.tools import tool
from langchain.tools import InjectedState
from langchain_core.documents import Document
from langgraph.types import interrupt

# å¯¼å…¥ä½ ç°æœ‰çš„æ ¸å¿ƒç±»
from core.rag_chain import SelfRAGChain
from config.setting import RAGConfig
from core.agent_schemas import (
    RetrieveInput, EvaluateInput, OCRInput,
    HumanReviewInput, SystemStatusInput
)


# å…¨å±€ä¸Šä¸‹æ–‡ï¼ˆæ›¿ä»£ä¾èµ–æ³¨å…¥ï¼‰
class ToolContext:
    """å·¥å…·ä¸Šä¸‹æ–‡ï¼šå­˜å‚¨RAGé“¾å’Œé…ç½®çš„å¼•ç”¨"""

    def __init__(self):
        self.rag_chain: Optional[SelfRAGChain] = None
        self.config: Optional[RAGConfig] = None

    def init(self, rag: SelfRAGChain, cfg: RAGConfig):
        """åˆå§‹åŒ–ï¼ˆåœ¨Agentå¯åŠ¨æ—¶è°ƒç”¨ï¼‰"""
        self.rag_chain = rag
        self.config = cfg


# åˆ›å»ºå…¨å±€å®ä¾‹
ctx = ToolContext()


def init_agent_context(rag: SelfRAGChain, cfg: RAGConfig):
    """ä¾›Agentåˆå§‹åŒ–çš„æ¥å£"""
    ctx.init(rag, cfg)


@tool(args_schema=RetrieveInput, response_format="content_and_artifact")
async def retrieve_knowledge(
        query: str,
        top_k: int = 3,
        use_rerank: bool = True,
        state: Annotated[Optional[dict], InjectedState] = None  # ç±»å‹æ”¹ä¸º Optional[dict]
) -> tuple[str, List[Document]]:
    """
    ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³æ–‡æ¡£ã€‚å›ç­”äº‹å®æ€§é—®é¢˜å‰å¿…é¡»å…ˆè°ƒç”¨æ­¤å·¥å…·ã€‚
    è¿”å›æ ¼å¼åŒ–çš„æ–‡æ¡£æ‘˜è¦ï¼ˆç»™LLMï¼‰å’ŒåŸå§‹Documentå¯¹è±¡ï¼ˆç»™è¯„ä¼°å™¨ï¼‰ã€‚
    """
    if not ctx.rag_chain or not ctx.rag_chain.retriever:
        raise ValueError("çŸ¥è¯†åº“æœªåˆå§‹åŒ–")

    # æ£€æŸ¥è¿­ä»£æ¬¡æ•°é˜²æ­¢æ— é™å¾ªç¯
    current_iter = state.get("iteration_count", 0) if state else 0
    if current_iter >= ctx.config.max_iterations:
        return "å·²è¾¾åˆ°æœ€å¤§æ£€ç´¢è¿­ä»£æ¬¡æ•°", []

    # æ‰§è¡Œæ£€ç´¢
    docs = await ctx.rag_chain.retriever.retrieve(query)

    # æ ¼å¼åŒ–ç»™LLMé˜…è¯»çš„å†…å®¹
    content_parts = [f"æ£€ç´¢åˆ° {len(docs)} ç¯‡ç›¸å…³æ–‡æ¡£ï¼š"]
    for i, doc in enumerate(docs[:top_k], 1):
        source = doc.metadata.get("source", "unknown")
        score = (
                doc.metadata.get("rerank_score") or
                doc.metadata.get("vector_score") or
                doc.metadata.get("bm25_score", 0)
        )
        preview = doc.page_content[:200].replace("\n", " ")
        content_parts.append(f"[{i}] {source}(ç›¸å…³åº¦:{score:.2f}): {preview}...")

    return "\n".join(content_parts), docs[:top_k]


@tool(args_schema=EvaluateInput, response_format="content")
def evaluate_answer_quality(
        query: str,
        answer: str,
        contexts: List[str] = None,
        state: Annotated[Optional[dict], InjectedState] = None
) -> str:
    """
    è¯„ä¼°ç”Ÿæˆç­”æ¡ˆçš„è´¨é‡ï¼Œæ£€æµ‹å¹»è§‰é£é™©å’Œç½®ä¿¡åº¦ã€‚
    å¿…é¡»åœ¨ç”Ÿæˆç­”æ¡ˆåè°ƒç”¨æ­¤å·¥å…·è¿›è¡Œè‡ªæ£€ã€‚
    å¦‚æœç½®ä¿¡åº¦ä½äºé˜ˆå€¼ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ ‡è®°éœ€è¦äººå·¥å®¡æ ¸ã€‚
    """
    if not ctx.rag_chain:
        return "è¯„ä¼°å™¨æœªåˆå§‹åŒ–"

    # ä¿®å¤ï¼šå˜é‡åä» ctx æ”¹ä¸º textï¼Œé¿å…é®è”½å…¨å±€ ctx
    docs = [Document(page_content=text) for text in (contexts or [])]

    # å¤ç”¨ä½ ç°æœ‰çš„evaluatorï¼ˆé¿å…é‡å¤ä»£ç ï¼‰
    review = ctx.rag_chain.evaluator.evaluate(
        query=query,
        answer=answer,
        documents=docs,
        latency_ms=0
    )

    # æ„å»ºè¯¦ç»†æŠ¥å‘Š
    lines = [
        "ã€Self-RAGè¯„ä¼°æŠ¥å‘Šã€‘",
        f"ç½®ä¿¡åº¦: {review.confidence:.0%} (é˜ˆå€¼: {ctx.config.human_review_threshold:.0%})",
        f"å¹»è§‰é£é™©: {review.hallucination_risk:.0%} {'âš ï¸é«˜é£é™©' if review.hallucination_risk > 0.5 else 'âœ…æ­£å¸¸'}",
        f"æ£€ç´¢ç›¸å…³æ€§: {review.retrieval_relevance:.2f}",
        f"å®Œæ•´æ€§: {review.answer_completeness:.2f}"
    ]

    # å¦‚æœè§¦å‘å®¡æ ¸æ¡ä»¶ï¼Œåœ¨Stateä¸­æ ‡è®°ï¼ˆä¾›GraphèŠ‚ç‚¹è¯»å–ï¼‰
    if review.needs_human_review and state is not None:
        lines.append(f"\nâš ï¸ è§¦å‘äººå·¥å®¡æ ¸æ¡ä»¶ï¼Œä»»åŠ¡IDå°†ç”Ÿæˆ")

    return "\n".join(lines)


@tool(args_schema=OCRInput, response_format="content")
async def process_document(
        file_path: str,
        language: str = "chi_sim+eng",
        auto_index: bool = True,
        state: Annotated[Optional[dict], InjectedState] = None
) -> str:
    """
    å¤„ç†ä¸Šä¼ çš„å›¾ç‰‡æˆ–PDFæ–‡æ¡£ï¼Œæå–æ–‡å­—å†…å®¹ã€‚
    å½“ç”¨æˆ·ä¸Šä¼ æ–‡ä»¶å¹¶è¯¢é—®å…¶ä¸­å†…å®¹æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚
    """
    from core.ocr_processor import OCRProcessor

    processor = OCRProcessor(language=language, enabled=True)
    if not processor.is_available():
        return "âŒ OCRåŠŸèƒ½ä¸å¯ç”¨ï¼ˆè¯·å®‰è£…Tesseract: apt-get install tesseract-ocr-chi-simï¼‰"

    try:
        path = Path(file_path)
        if not path.exists():
            return f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"

        text = await processor.extract_text(path)

        if not text:
            return "âš ï¸ æœªèƒ½ä»æ–‡ä»¶ä¸­è¯†åˆ«åˆ°æ–‡å­—å†…å®¹"

        # è‡ªåŠ¨ç´¢å¼•åˆ°çŸ¥è¯†åº“ï¼ˆä¿æŒæ•°æ®æ–°é²œåº¦ï¼‰
        if auto_index and ctx.rag_chain:
            await ctx.rag_chain.aindex_documents(
                texts=[text],
                metadatas=[{
                    "source": f"upload_{path.name}",
                    "type": "ocr_document",
                    "original_path": str(path)
                }]
            )
            index_info = f"ï¼ˆå·²è‡ªåŠ¨ç´¢å¼•åˆ°çŸ¥è¯†åº“ï¼‰"
        else:
            index_info = ""

        return f"âœ… OCRè¯†åˆ«æˆåŠŸ{index_info}ï¼Œå…±{len(text)}å­—ç¬¦ï¼š\n\n{text[:800]}{'...' if len(text) > 800 else ''}"

    except Exception as e:
        return f"âŒ å¤„ç†å¤±è´¥: {str(e)}"


@tool(args_schema=HumanReviewInput, response_format="content")
def trigger_human_review(
        reason: str,
        suggestion: Optional[str] = None,  # è¿™é‡Œä¹Ÿè¦ Optional
        state: Annotated[Optional[dict], InjectedState] = None
) -> str:
    """
    è§¦å‘äººå·¥å®¡æ ¸æµç¨‹ã€‚å½“è¯„ä¼°æ˜¾ç¤ºç½®ä¿¡åº¦è¿‡ä½æˆ–æ£€æµ‹åˆ°é«˜é£é™©æ—¶ï¼Œ
    è°ƒç”¨æ­¤å·¥å…·æš‚åœæ‰§è¡Œå¹¶ç­‰å¾…äººå·¥ä»‹å…¥ã€‚
    """
    if not ctx.rag_chain:
        return "ç³»ç»Ÿæœªåˆå§‹åŒ–"

    # ç”Ÿæˆä»»åŠ¡ID
    import uuid
    task_id = f"review_{uuid.uuid4().hex[:8]}"

    # è·å–å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆä»Stateä¸­ï¼‰
    last_answer = ""
    if state:  # æ·»åŠ æ£€æŸ¥é¿å… state ä¸º None
        for msg in reversed(state.get("messages", [])):
            if hasattr(msg, 'content') and not hasattr(msg, 'tool_calls'):
                last_answer = msg.content
                break

    # å­˜å‚¨åˆ°å®¡æ ¸é˜Ÿåˆ—ï¼ˆå¤ç”¨ä½ ç°æœ‰çš„review_tasksæœºåˆ¶ï¼‰
    ctx.rag_chain.review_tasks[task_id] = {
        "task_id": task_id,
        "query": state.get("last_query", "unknown") if state else "unknown",
        "original_answer": last_answer,
        "status": "pending",
        "reason": reason,
        "suggestion": suggestion
    }

    # ä½¿ç”¨ interrupt æš‚åœæ‰§è¡Œï¼ˆLangGraph 1.0+ APIï¼‰
    result = interrupt({
        "type": "human_review_required",
        "task_id": task_id,
        "reason": reason,
        "original_answer": last_answer,
        "available_actions": ["approved", "rejected", "modified"]
    })

    # resumeåè¿”å›ç»“æœ
    action = result.get("action", "unknown")
    return f"âœ… äººå·¥å®¡æ ¸å®Œæˆ: {action}"


@tool(args_schema=SystemStatusInput, response_format="content")
def check_system_status(
        detail: bool = False,
        state: Annotated[Optional[dict], InjectedState] = None
) -> str:
    """
    æŸ¥è¯¢Self-RAGç³»ç»Ÿè¿è¡ŒçŠ¶æ€å’Œé…ç½®ä¿¡æ¯ã€‚
    ç”¨äºè¿ç»´æ£€æŸ¥æˆ–å‘ç”¨æˆ·å±•ç¤ºç³»ç»Ÿæ¦‚å†µã€‚
    """
    if not ctx.rag_chain or not ctx.config:
        return "ç³»ç»Ÿå°šæœªåˆå§‹åŒ–"

    cfg = ctx.config
    rag = ctx.rag_chain

    lines = [
        "ğŸ“Š Self-RAGç³»ç»ŸçŠ¶æ€",
        f"â€¢ LLMæ¨¡å‹: {cfg.llm_model}",
        f"â€¢ Embeddingæ¨¡å‹: {cfg.embedding_model}",
        f"â€¢ æ–‡æ¡£æ€»æ•°: {len(rag.retriever.hybrid_retriever.documents) if rag.retriever else 0}",
        f"â€¢ æ··åˆæ£€ç´¢: {'BM25 + Vector' if cfg.hybrid_weights else 'ä»…Vector'}",
        f"â€¢ é‡æ’åº: {'å·²å¯ç”¨' if cfg.reranker_enabled else 'å·²ç¦ç”¨'}",
        f"â€¢ äººå·¥å®¡æ ¸: {'å·²å¯ç”¨' if cfg.human_review_enabled else 'å·²ç¦ç”¨'}",
        f"â€¢ å¾…å®¡æ ¸ä»»åŠ¡: {len([t for t in rag.review_tasks.values() if t['status'] == 'pending'])}"
    ]

    if detail:
        lines.extend([
            f"\nâš™ï¸ è¯¦ç»†é…ç½®:",
            f"â€¢ åˆ†å—å¤§å°: {cfg.chunk_size}",
            f"â€¢ é‡å é•¿åº¦: {cfg.chunk_overlap}",
            f"â€¢ æœ€å¤§è¿­ä»£: {cfg.max_iterations}",
            f"â€¢ ç½®ä¿¡åº¦é˜ˆå€¼: {cfg.confidence_threshold}",
            f"â€¢ OCRçŠ¶æ€: {'å·²å¯ç”¨' if cfg.ocr_enabled else 'å·²ç¦ç”¨'}"
        ])

    return "\n".join(lines)